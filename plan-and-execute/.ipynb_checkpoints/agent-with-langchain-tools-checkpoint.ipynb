{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d476163-8d8e-48a4-bbf7-1bf00708ca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "Define ChatGPT API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aca4f478-b4cb-41da-87c9-65187f513be3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]=\"sk-hOr05iYuiLO6LPP9xTliqOrxqKChEUs1TPI9EopYV1Lx86te\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9854c2b-a578-46fc-a3b1-e0748c1dd1f0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1197813033.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    Create LLM\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Create LLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0eefe204-b554-4b1b-8421-0f9fd1127e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", base_url=\"https://use.52apikey.cn/v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697b2eda-5de0-4b0e-98aa-c2a7f59b655f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Define the file management tools provided by langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d8dc946-77f0-4aee-b2b6-97ce64cc0784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CopyFileTool(root_dir='/Users/shuai.an/Desktop/DevSpace/idea_workspace/AI/ai-agent/plan-and-execute/output/'),\n",
       " DeleteFileTool(root_dir='/Users/shuai.an/Desktop/DevSpace/idea_workspace/AI/ai-agent/plan-and-execute/output/'),\n",
       " FileSearchTool(root_dir='/Users/shuai.an/Desktop/DevSpace/idea_workspace/AI/ai-agent/plan-and-execute/output/'),\n",
       " MoveFileTool(root_dir='/Users/shuai.an/Desktop/DevSpace/idea_workspace/AI/ai-agent/plan-and-execute/output/'),\n",
       " ReadFileTool(root_dir='/Users/shuai.an/Desktop/DevSpace/idea_workspace/AI/ai-agent/plan-and-execute/output/'),\n",
       " WriteFileTool(root_dir='/Users/shuai.an/Desktop/DevSpace/idea_workspace/AI/ai-agent/plan-and-execute/output/'),\n",
       " ListDirectoryTool(root_dir='/Users/shuai.an/Desktop/DevSpace/idea_workspace/AI/ai-agent/plan-and-execute/output/')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.agent_toolkits import FileManagementToolkit\n",
    "from tempfile import TemporaryDirectory\n",
    "import os\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "working_directory = TemporaryDirectory()\n",
    "toolkit = FileManagementToolkit(\n",
    "    root_dir=str(current_directory+\"/output/\")\n",
    ")  # If you don't provide a root_dir, operations will default to the current working directory\n",
    "tools = toolkit.get_tools()\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a6cda8-e48c-4a78-bf9c-a7a9e6d7b2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Create Agent to use above tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c28cee3f-910c-433d-b064-92c358a54df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "# Initialize memory to persist state between graph runs\n",
    "checkpointer = MemorySaver()\n",
    "prompt = \"\"\"\n",
    "Your are a smart assistant. Please think step-by-step when answering the new question, and provide a well-read answer to the user.\n",
    "\n",
    "You are given a number of tools as functions, you must use one of those tools and fillup \n",
    "all the parameters of those tools ,whose answers you will get from the given situation.\n",
    "\n",
    "First analyze the given situation to fully understand what is the intention of the user,\n",
    "what they need and exactly which tool will fill up that necessity.\n",
    "Then look into the parameters and extract all the relevant informations to fill up the \n",
    "parameter with right values.\n",
    "Finally, call the tool with the right parameters and provide the answer to the user.\n",
    "\n",
    "\"\"\"\n",
    "# \"\"\"\n",
    "# ---For example---\n",
    "# Question:\"I am in Shanghai, what should I wear today?\".\n",
    "# Thinking:\n",
    "# first, you need to search the temperature in Shanghai, and then search the clothes based on the temperature.\n",
    "# second, you need to call search_temperature with location \"Shanghai\" and call search_clothes with the temperature you get from search_temperature.\n",
    "# Answer: The weather in Shanghai is sunny with temperatures 29-35Â°C. Need to wear a T-shirt.\n",
    "# ---For example---\n",
    "# \"\"\"\n",
    "agent_executor = create_react_agent(llm, tools,prompt=prompt, checkpointer=checkpointer)\n",
    "config = {\"configurable\": {\"thread_id\": 42}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5239d89f-cdc8-4af2-bd58-2699979079b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Create a file and list the files in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a61d5939-e288-447a-a90c-86b2117edfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '0194f942003713dc3f2d10f9a1685b4e', 'function': {'arguments': '{\"file_path\": \"example.txt\", \"text\": \"aaa\"}', 'name': \"\\nTo write the text 'aaa' into the file 'example.txt', I need to use the `write_file` function. This function requires two parameters: `file_path` and `text`.\\n\\n1. `file_path`: The file where the text will be written, which is 'example.txt'.\\n2. `text`: The text to be written into the file, which is 'aaa'.\\n\\nNow, I will call the `write_file` function with the appropriate parameters.\\n\\n```json\"}, 'type': 'function'}, {'id': '0194f942003782e47720acac79df9508', 'function': {'arguments': '{\"file_path\": \"example.txt\", \"text\": \"aaa\"}', 'name': '\\n```write_file'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 131, 'prompt_tokens': 1107, 'total_tokens': 1238, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'Pro/THUDM/glm-4-9b-chat', 'system_fingerprint': '', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-f1e24fc1-8958-4c1c-a864-3282bfefcae7-0', tool_calls=[{'name': \"\\nTo write the text 'aaa' into the file 'example.txt', I need to use the `write_file` function. This function requires two parameters: `file_path` and `text`.\\n\\n1. `file_path`: The file where the text will be written, which is 'example.txt'.\\n2. `text`: The text to be written into the file, which is 'aaa'.\\n\\nNow, I will call the `write_file` function with the appropriate parameters.\\n\\n```json\", 'args': {'file_path': 'example.txt', 'text': 'aaa'}, 'id': '0194f942003713dc3f2d10f9a1685b4e', 'type': 'tool_call'}, {'name': '\\n```write_file', 'args': {'file_path': 'example.txt', 'text': 'aaa'}, 'id': '0194f942003782e47720acac79df9508', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1107, 'output_tokens': 131, 'total_tokens': 1238, 'input_token_details': {}, 'output_token_details': {}})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content=\"Error: \\nTo write the text 'aaa' into the file 'example.txt', I need to use the `write_file` function. This function requires two parameters: `file_path` and `text`.\\n\\n1. `file_path`: The file where the text will be written, which is 'example.txt'.\\n2. `text`: The text to be written into the file, which is 'aaa'.\\n\\nNow, I will call the `write_file` function with the appropriate parameters.\\n\\n```json is not a valid tool, try one of [copy_file, file_delete, file_search, move_file, read_file, write_file, list_directory].\", name=\"\\nTo write the text 'aaa' into the file 'example.txt', I need to use the `write_file` function. This function requires two parameters: `file_path` and `text`.\\n\\n1. `file_path`: The file where the text will be written, which is 'example.txt'.\\n2. `text`: The text to be written into the file, which is 'aaa'.\\n\\nNow, I will call the `write_file` function with the appropriate parameters.\\n\\n```json\", id='2f5bdc30-1956-4ffe-a20a-df404d078b5f', tool_call_id='0194f942003713dc3f2d10f9a1685b4e', status='error'), ToolMessage(content='Error: \\n```write_file is not a valid tool, try one of [copy_file, file_delete, file_search, move_file, read_file, write_file, list_directory].', name='\\n```write_file', id='75584dab-6cbf-4098-95f1-0daf40c400de', tool_call_id='0194f942003782e47720acac79df9508', status='error')]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '0194f94203e85826f271cc103364c524', 'function': {'arguments': '{\"file_path\": \"example.txt\", \"text\": \"aaa\"}', 'name': 'write_file'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 1284, 'total_tokens': 1301, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'THUDM/glm-4-9b-chat', 'system_fingerprint': '', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-fea393a9-4809-4593-9153-ca96d63f36cc-0', tool_calls=[{'name': 'write_file', 'args': {'file_path': 'example.txt', 'text': 'aaa'}, 'id': '0194f94203e85826f271cc103364c524', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1284, 'output_tokens': 17, 'total_tokens': 1301, 'input_token_details': {}, 'output_token_details': {}})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content='File written successfully to example.txt.', name='write_file', id='16271a66-d926-4238-a99b-11beefeaf0d4', tool_call_id='0194f94203e85826f271cc103364c524')]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content=\"\\nThe text 'aaa' has been successfully written into the file 'example.txt'.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 1296, 'total_tokens': 1313, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'THUDM/glm-4-9b-chat', 'system_fingerprint': '', 'finish_reason': 'stop', 'logprobs': None}, id='run-cd7d8e29-9dc9-43c2-8030-fbb815117093-0', usage_metadata={'input_tokens': 1296, 'output_tokens': 17, 'total_tokens': 1313, 'input_token_details': {}, 'output_token_details': {}})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "        {\"messages\": [HumanMessage(content=\"write 'aaa' into file 'example.txt'\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2918595c-5bfe-48d7-9e18-9f98394cd6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '0194f94218c95eecc2da43165c3998e9', 'function': {'arguments': '{}', 'name': 'list_directory'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 1324, 'total_tokens': 1328, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'THUDM/glm-4-9b-chat', 'system_fingerprint': '', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-10e40963-c1ce-46d1-9d09-6c49722b0dc2-0', tool_calls=[{'name': 'list_directory', 'args': {}, 'id': '0194f94218c95eecc2da43165c3998e9', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1324, 'output_tokens': 4, 'total_tokens': 1328, 'input_token_details': {}, 'output_token_details': {}})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content='example.txt\\n.ipynb_checkpoints', name='list_directory', id='b2991aaa-af1f-41eb-b028-8ec08f07fe66', tool_call_id='0194f94218c95eecc2da43165c3998e9')]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content='\\nThe following files are found in the directory:\\n1. example.txt\\n2. .ipynb_checkpoints', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 1337, 'total_tokens': 1360, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'Pro/THUDM/glm-4-9b-chat', 'system_fingerprint': '', 'finish_reason': 'stop', 'logprobs': None}, id='run-9e1492f0-4090-4ae0-9abd-2434fc7cd5fd-0', usage_metadata={'input_tokens': 1337, 'output_tokens': 23, 'total_tokens': 1360, 'input_token_details': {}, 'output_token_details': {}})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "        {\"messages\": [HumanMessage(content=\"please list all the files in the directory\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f955bc8-438d-4b11-bed6-02c8553fbbc9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '0194f942d377b0f57fdd55b9384bb8ab', 'function': {'arguments': '{\"file_path\": \"example.txt\"}', 'name': 'file_delete'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 1382, 'total_tokens': 1393, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'THUDM/glm-4-9b-chat', 'system_fingerprint': '', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-0e28cc44-0e35-49b5-a9f1-d98e7df08ec5-0', tool_calls=[{'name': 'file_delete', 'args': {'file_path': 'example.txt'}, 'id': '0194f942d377b0f57fdd55b9384bb8ab', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1382, 'output_tokens': 11, 'total_tokens': 1393, 'input_token_details': {}, 'output_token_details': {}})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content='File deleted successfully: example.txt.', name='file_delete', id='9f51bc5f-95ac-4375-a7d6-7a1f5ff59e4e', tool_call_id='0194f942d377b0f57fdd55b9384bb8ab')]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content=\"\\nThe file 'example.txt' has been successfully deleted from the directory.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 1394, 'total_tokens': 1409, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'Pro/THUDM/glm-4-9b-chat', 'system_fingerprint': '', 'finish_reason': 'stop', 'logprobs': None}, id='run-aea01c1b-80b7-427e-a4fe-1b2864edf645-0', usage_metadata={'input_tokens': 1394, 'output_tokens': 15, 'total_tokens': 1409, 'input_token_details': {}, 'output_token_details': {}})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "        {\"messages\": [HumanMessage(content=\"delete the file 'example.txt' in the directory\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64bff03-351f-4fe8-ae9c-6042af589e79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
